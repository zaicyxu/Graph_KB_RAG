# -*- coding: utf-8 -*-
#!/usr/bin/env python

"""
@Project Name: KnowledgeGraph_ExpertSystem
@File Name: Verify_Knowledgebase.py
@Software: Python
@Time: Mar/2025
@Author: Yufei Quan, Rui Xu
@Version: 0.6.4
@Description: RAG & Gemini Answer Comparison with Ground Truth
"""

import csv
from fuzzywuzzy import fuzz
import google.generativeai as genai
import re

from main_RAG.main_rag_dynamatic_search import Neo4jRAGSystem
from main_RAG.main_rag_dynamatic_masked import Neo4jRAGSystem as Neo4jRAGSystemMasked
from query_generation import QuestionGenerator
from porlog import configuration
from main_RAG import configuration_2
import configuration_3

# Ensure Gemini API is configured
genai.configure(api_key=configuration.GEMINI_API_KEY)

class ExperimentRunner:
    def __init__(self, top_k=3, similarity_threshold=0.5, num_questions=20):
        """
        Initialize the experiment runner with the specified parameters.
        """
        self.top_k = top_k
        self.similarity_threshold = similarity_threshold
        self.num_questions = num_questions

        # Initialize the RAG systems and Question Generator.
        self.rag_system_all = Neo4jRAGSystem(
            configuration_2.NEO4J_URI, configuration_2.NEO4J_USER, configuration_2.NEO4J_PASSWORD
        )
        self.rag_system_masked = Neo4jRAGSystemMasked(
            configuration_3.NEO4J_URI, configuration_2.NEO4J_USER, configuration_2.NEO4J_PASSWORD
        )
        self.question_generator = QuestionGenerator()

    def get_gemini_answer(self, question):
        """
        Call Gemini LLM to answer the question with a structured format.
        """
        prompt = f"""
        You are an expert in knowledge graph analysis. Answer the following question in a structured format.
        - If the answer is uncertain, infer the most reasonable response based on related entities and relationships.
        - Do NOT answer "I don't know" or "No information available".
        - First, provide a structured knowledge graph answer using this format:
            (Entity A)-[:Relationship]->(Entity B)
            (Entity C)-[:Relationship]->(Entity D)
        - Then, provide a detailed step-by-step explanation of the inference process.

        Question: {question}
        Answer:
        """
        try:
            model = genai.GenerativeModel("gemini-2.0-flash")
            response = model.generate_content(prompt)

            if hasattr(response, "text"):
                answer = "\n".join([line.strip() for line in response.text.split("\n") if line.strip()])
                return answer
            else:
                print("Debug - Response Structure:", dir(response))
                return "Error: Invalid response structure from Gemini."

        except Exception as e:
            print(f"Error generating Gemini answer: {repr(e)}")
            return "Error: No answer generated by Gemini."

    def extract_labels_from_answer(self, answer_text):
        """
        Extract entity labels from the structured answer.
        """
        pattern = r'\(([^)]+)\)'
        matches = re.findall(pattern, answer_text)
        return list(set(match.lower().strip() for match in matches if match.strip()))

    def preprocess_label(self, label):
        """
        Preprocess a label: lower-case, remove punctuation, and filter out stopwords.
        """
        label = label.lower().strip()
        label = re.sub(r'[^\w\s]', '', label)
        # Getting stopwords
        stopwords = {"the", "and", "of", "in", "a", "an"}
        tokens = label.split()
        tokens = [token for token in tokens if token not in stopwords]
        return " ".join(tokens)

    def compute_rouge_accuracy(self, predicted_triples, ground_truth_triples, fuzzy_threshold=80):
        parsed_ground_truth = set()

        # First ensure ground_truth_triples is a list of strings
        if not isinstance(ground_truth_triples, (list, tuple)):
            print(f"[ERROR] ground_truth_triples must be a list, got {type(ground_truth_triples)}")
            return 0.0

        for triple in ground_truth_triples:
            # Ensure triple is a string
            if not isinstance(triple, str):
                print(f"[WARNING] Skipping non-string ground truth triple: {triple}")
                continue

            # Try multiple possible formats
            match = None
            patterns = [
                r"^\s*\(?\s*([\w\-\.]+)\s*\)?\s*-\s*\[?:\s*([\w\-]+)\s*\]?\s*->\s*\(?\s*([\w\-\.]+)\s*\)?\s*$",
                # With or without brackets
                r"^\s*([\w\-\.]+)\s*-\s*([\w\-]+)\s*->\s*([\w\-\.]+)\s*$"  # Simple format
            ]

            for pattern in patterns:
                match = re.match(pattern, triple)
                if match:
                    break

            if match:
                subj = match.group(1).strip().lower().replace("_", "")
                rel = match.group(2).strip().lower()
                obj = match.group(3).strip().lower().replace("_", "")
                parsed_ground_truth.add((subj, rel, obj))
            else:
                print(f"[WARNING] Invalid ground truth triple format: {triple}")

        # Process predicted triples
        parsed_predicted = []
        for triple in predicted_triples:
            if isinstance(triple, (list, tuple)) and len(triple) == 3:
                # If it's already a decomposed triple
                subj = re.sub(r"[^\w\-\.]", "", str(triple[0])).strip().lower().replace("_", "")
                rel = re.sub(r"[^\w\-]", "", str(triple[1])).strip().lower()
                obj = re.sub(r"[^\w\-\.]", "", str(triple[2])).strip().lower().replace("_", "")
                parsed_predicted.append((subj, rel, obj))
            elif isinstance(triple, str):
                # If it's a string triple, try to parse it
                for pattern in patterns:
                    match = re.match(pattern, triple)
                    if match:
                        subj = match.group(1).strip().lower().replace("_", "")
                        rel = match.group(2).strip().lower()
                        obj = match.group(3).strip().lower().replace("_", "")
                        parsed_predicted.append((subj, rel, obj))
                        break
                else:
                    print(f"[WARNING] Invalid predicted triple format: {triple}")
            else:
                print(f"[WARNING] Skipping invalid predicted triple: {triple}")

        if not parsed_predicted or not parsed_ground_truth:
            return 0.0

        match_count = 0
        for pred in parsed_predicted:
            if pred in parsed_ground_truth:
                match_count += 1
            else:
                # Calculate fuzzy matching if we have ground truth
                scores = []
                for gt in parsed_ground_truth:
                    subject_score = fuzz.ratio(pred[0], gt[0])
                    relation_score = fuzz.ratio(pred[1], gt[1])
                    object_score = fuzz.ratio(pred[2], gt[2])
                    scores.append((subject_score + relation_score + object_score) / 3)

                if scores and max(scores) >= fuzzy_threshold:
                    match_count += 1

        accuracy = match_count / len(parsed_predicted) if parsed_predicted else 0.0
        return round(accuracy, 3)

    def _generate_ground_truth(self, question):
        entities = self.rag_system_all.extract_keywords(question)
        if not entities:
            print(f"[WARNING] No keywords extracted from `{question}`.")
            return set()

        ground_truth = set()
        with self.rag_system_all.driver.session() as session:
            for entity in entities:
                cypher_query = f"""
                MATCH (n)-[r]->(m)
                WHERE toLower(n.Name) CONTAINS toLower('{entity}')
                RETURN n.Name AS node_name, type(r) AS relation_name, m.Name AS connected_node
                LIMIT 50
                """
                result = session.run(cypher_query)
                for record in result:
                    # Format with parentheses and square brackets
                    ground_truth.add(
                        f"({record['node_name']})-[:{record['relation_name']}]->({record['connected_node']})")

        if not ground_truth:
            print(f"[WARNING] No ground truth found for `{question}`.")
        return ground_truth

    def run_experiment(self, output_file="experiment_results.csv"):
        """
        Run the experiment: generate questions, get answers from RAG (all data), RAG (masked), Gemini & Ground Truth, compute Hit@1, and save results.
        """
        questions_with_categories = self.question_generator.generate_questions(self.num_questions)

        with open(output_file, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, quoting=csv.QUOTE_ALL)
            # Header: each row will contain question, ground truth (structured triples), Expert System answer triples,
            # Gemini answer triples, Expert System accuracy, Gemini accuracy, and question category.
            header = ["Question", "Ground Truth Triples", "Masked System Answer Triples", "Gemini Answer Triples",
                      "Masked System Accuracy", "Gemini Accuracy", "Category"]
            writer.writerow(header)

            for question_entry in questions_with_categories:
                question, category = question_entry
                print(f"\nProcessing question: {question} (Category: {category})")

                # Retrieve answer from KB System (masked) and from Gemini
                entities_kb = self.rag_system_masked.retrieve_relevant_entities(question)
                answer_masked = self.rag_system_masked.generate_answer(question, entities_kb)
                gemini_answer = self.get_gemini_answer(question)

                # Generate ground truth structured triples from the knowledge graph
                # ground_truth_set = self._generate_ground_truth(question)
                # gt_triples = []
                ground_truth_set = self._generate_ground_truth(question)
                gt_triples = list(ground_truth_set)
                gt_pattern = r'\(\s*([^)]+?)\s*\)-\[:\s*([^)]+?)\s*\]->\(\s*([^)]+?)\s*\)'
                for gt in ground_truth_set:
                    m = re.match(gt_pattern, gt)
                    if m:
                        subj = m.group(1).lower().strip()
                        rel = m.group(2).lower().strip()
                        obj = m.group(3).lower().strip()
                        gt_triples.append((subj, rel, obj))
                    else:
                        print(f"[WARNING] Ground truth triple format invalid: {gt}")

                # Extract structured triples from the answer texts using regex
                def extract_triples(answer_text):
                    pattern = r'\(\s*([^)]+?)\s*\)-\[:\s*([^)]+?)\s*\]->\(\s*([^)]+?)\s*\)'
                    matches = re.findall(pattern, answer_text)
                    triples = []
                    for match in matches:
                        subj = match[0].lower().strip()
                        rel = match[1].lower().strip()
                        obj = match[2].lower().strip()
                        triples.append((subj, rel, obj))
                    return triples

                masked_triples = extract_triples(answer_masked)
                gemini_triples = extract_triples(gemini_answer)

                # Compute ROUGE-based exact match accuracy for each system
                masked_accuracy = self.compute_rouge_accuracy(masked_triples, gt_triples)
                gemini_accuracy = self.compute_rouge_accuracy(gemini_triples, gt_triples)

                # Format triples for CSV output: join each triple as a string and then join them with " | "
                def format_triples(triples):
                    return " | ".join([f"({s})-[:{r}]->({o})" for s, r, o in triples])

                masked_triples_str = format_triples(masked_triples)
                gemini_triples_str = format_triples(gemini_triples)
                gt_triples_str = " | ".join(ground_truth_set)

                # Write results as one row in CSV (all fields in one row, horizontally)
                writer.writerow([
                    question,
                    gt_triples_str,
                    masked_triples_str,
                    gemini_triples_str,
                    masked_accuracy,
                    gemini_accuracy,
                    category
                ])

                print(f"Question: {question}")
                print(f"Ground Truth Triples: {gt_triples_str}")
                print(f"KB masked System Answer Triples: {masked_triples_str}")
                print(f"Gemini Answer Triples: {gemini_triples_str}")
                print(f"KB maked System Accuracy: {masked_accuracy}")
                print(f"Gemini Accuracy: {gemini_accuracy}")
                print(f"Category: {category}")

    def close(self):
        self.question_generator.close()
        self.rag_system_all.close()
        self.rag_system_masked.close()

if __name__ == "__main__":
    experiment = ExperimentRunner(top_k=5, similarity_threshold=0.7, num_questions=20)
    experiment.run_experiment("experiment_results_test.csv")
    experiment.close()